{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Regressionist/Stock-prediction-Dual-Attention-based-RNN-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('data/train.csv')\n",
    "validation_df=pd.read_csv('data/validation.csv')\n",
    "validation_df=pd.concat([train_df[-9:],validation_df])\n",
    "validation_df=validation_df.reset_index(drop=True)\n",
    "test_df=pd.read_csv('data/test.csv')\n",
    "train_df.drop(['High', 'Low', 'Timestamp'],axis=1,inplace=True)\n",
    "validation_df.drop(['High', 'Low', 'Timestamp'],axis=1,inplace=True)\n",
    "test_df.drop(['High', 'Low','Timestamp'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataprep(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df=dataframe\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]-10\n",
    "    def __getitem__(self,idx):\n",
    "        if (idx+10<self.df.shape[0]):\n",
    "            X=torch.from_numpy(self.df.drop('Close',axis=1)[idx:idx+10].values)\n",
    "            targets=torch.from_numpy(self.df['Close'][idx:idx+9].values)\n",
    "            y=torch.tensor([self.df['Close'].loc[idx+9]])\n",
    "            return ({'X':X, 'targets':targets, 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=dataprep(dataframe=train_df)\n",
    "validation_set=dataprep(dataframe=validation_df)\n",
    "test_set=dataprep(dataframe=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 torch.Size([10, 2]) torch.Size([9]) torch.Size([1])\n",
      "61 torch.Size([10, 2]) torch.Size([9]) torch.Size([1])\n",
      "62 torch.Size([10, 2]) torch.Size([9]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(60,63):\n",
    "    sample=validation_set[i]\n",
    "    print (i,sample['X'].size(),sample['targets'].size(), sample['y'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9613"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(validation_set, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def init_hidden(x, hidden_size: int):\n",
    "    return torch.zeros(1, x.size(0), hidden_size, device=device)\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,encoder_input_size=16,encoder_hidden_size=64, time_steps=10):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.input_size=encoder_input_size\n",
    "        #input_size=n\n",
    "        self.hidden_size=encoder_hidden_size\n",
    "        #hidden_size=1\n",
    "        self.t_steps=time_steps\n",
    "        #time_steps=10\n",
    "        \n",
    "        self.input_attention=nn.Linear(time_steps+encoder_hidden_size,1)\n",
    "        self.rnn=nn.GRU(self.input_size, self.hidden_size)\n",
    "        \n",
    "#    def forward(self,encoder_input,batch_size,hidden):\n",
    "    def forward(self,encoder_input,batch_size):\n",
    "#        print(\"encoder_input: \", encoder_input.shape)\n",
    "#        print(\"input_size: \", self.input_size)\n",
    "        \n",
    "        batch_size = encoder_input.size(0)\n",
    "\n",
    "        #encoder_input:batch,T,n\n",
    "        encoder_input=encoder_input.permute(0,2,1) #batch,n,T\n",
    "        #print (encoder_input.size())\n",
    "        #hidden=self.initHidden(batch_size) #hidden : 1,batch,hidden_size\n",
    "        #print (hidden.size())\n",
    "        encoded = torch.zeros(batch_size, self.t_steps, self.hidden_size,device=device) #encoded: 1,T,hidden_size\n",
    "        \n",
    "        hidden = init_hidden(encoder_input, self.hidden_size)\n",
    " #       print(\"hidden: \", hidden.shape)\n",
    "\n",
    "        #print(encoded.size())\n",
    "        for t in range(self.t_steps):\n",
    "            x=torch.cat((hidden.repeat(self.input_size,1,1).permute(1,0,2),encoder_input),dim=2)\n",
    "            #print (x.size())\n",
    "            #x:batch,n,T+hidden_size\n",
    "            x=x.view(-1,self.t_steps+self.hidden_size)\n",
    "            #print (x.size())\n",
    "            #x:batch*n,T+hidden_size\n",
    "            x=F.softmax((self.input_attention(x)).view(-1,self.input_size),dim=1)\n",
    "            #print (x.size())\n",
    "            #print(encoder_input[:,t,:].size())\n",
    "            #x:batch,n\n",
    "            x=torch.mul(x,encoder_input[:,:,t])\n",
    "            #print (x.size())\n",
    "            #x:1,n\n",
    "            output, hidden=self.rnn(x.unsqueeze(0), hidden)\n",
    "            #print (output.size(), hidden.size())\n",
    "            encoded[:,t,:]=hidden\n",
    "            #output,hidden:1,1,hidden\n",
    "        return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self,decoder_hidden_size=64,encoder_hidden_size=64,decoder_input_size=1, time_steps=10):\n",
    "        super(DecoderRNN,self).__init__()\n",
    "        self.decoder_hidden_size=decoder_hidden_size\n",
    "        self.encoder_hidden_size=encoder_hidden_size\n",
    "        self.decoder_input_size=decoder_input_size\n",
    "        self.t_steps=time_steps\n",
    "        \n",
    "        self.temporal_attention=nn.Linear(decoder_hidden_size+encoder_hidden_size, 1)\n",
    "        self.rnn=nn.GRU(decoder_input_size,decoder_hidden_size)\n",
    "        self.fc1 = nn.Linear(encoder_hidden_size + 1, 1)\n",
    "        self.fc2 = nn.Linear(decoder_hidden_size + encoder_hidden_size, 1)\n",
    "        \n",
    "    def forward(self,encoded,y_history,batch_size):\n",
    "        #encoded: batch,T,hidden_size\n",
    "        #print (encoded.size())\n",
    "        \n",
    "        hidden = init_hidden(encoded, self.decoder_hidden_size)\n",
    "#        print(\"hidden: \", hidden.shape)\n",
    "\n",
    "        #y_history: batch,T-1\n",
    "        #hidden=self.initHidden(batch_size) #hidden:1,batch,hidden_size\n",
    "        #print (hidden.size())\n",
    "        for t in range(self.t_steps):\n",
    "            x=torch.cat((hidden.repeat(self.t_steps,1,1).permute(1,0,2), encoded), dim=2) \n",
    "            #x:batch,T,enc_hidden_size+dec_hidden_size\n",
    "            x=F.softmax(self.temporal_attention(x.view(-1,self.decoder_hidden_size+self.encoder_hidden_size)).view(-1,self.t_steps), dim=1)\n",
    "            #x:batch,T\n",
    "            x=torch.bmm(x.unsqueeze(1), encoded)[:,0,:]\n",
    "            #x:batch,hidden_size\n",
    "            if (t < self.t_steps-1):\n",
    "                y_tilda=self.fc1(torch.cat((x, y_history[:, t].unsqueeze(1)), dim=1))\n",
    "                output, hidden=self.rnn(y_tilda.unsqueeze(0), hidden)\n",
    "        y_pred=self.fc2(torch.cat((hidden[0], x), dim = 1))\n",
    "            \n",
    "        return y_pred\n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder,decoder,encoder_optimizer, decoder_optimizer, train_loader, loss_criterion, rl, num_epochs, epoch, epochs):\n",
    "    running_loss=0\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        x=Variable(sample['X'].type(torch.FloatTensor))\n",
    "        y=Variable(sample['targets'].type(torch.FloatTensor))\n",
    "        y_true=Variable(sample['y'].type(torch.FloatTensor))\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "#        hidden=encoder.initHidden(16)\n",
    "        encoded=encoder(x,16)\n",
    "#        hidden=decoder.initHidden(16)\n",
    "#        y_pred=decoder(encoded,y,16,hidden)\n",
    "        y_pred=decoder(encoded,y,16)\n",
    "        \n",
    "        loss=loss_criterion(y_pred,y_true)\n",
    "        running_loss+=loss.item()\n",
    "        rl.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "    print('Epoch: {}/{} | Loss: {}'.format(epoch-epochs+1, num_epochs, running_loss))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(y_pred,y_true):\n",
    "    r=0\n",
    "    for t in range(0,len(y_pred)-1):\n",
    "        if((y_pred[t+1]>=y_pred[t] and y_true[t+1]>=y_true[t]) or (y_pred[t+1]<y_pred[t] and y_true[t+1]<y_true[t])):\n",
    "            r=r+1\n",
    "    return r/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder,decoder, val_loader, loss_criterion, num_epochs, epoch, epochs):\n",
    "    eval_loss=0\n",
    "    y_predicted=[]\n",
    "    y_actual=[]\n",
    "    with torch.no_grad():\n",
    "        for i,sample in enumerate(val_loader):\n",
    "            x=sample['X'].type(torch.FloatTensor)\n",
    "            y=sample['targets'].type(torch.FloatTensor)\n",
    "            y_true=sample['y'].type(torch.FloatTensor)\n",
    "            \n",
    " #           hidden=encoder.initHidden(1)\n",
    "            encoded=encoder(x,1)\n",
    "#            hidden=decoder.initHidden(1)\n",
    "            y_pred=decoder(encoded,y,1)\n",
    "        \n",
    "            loss=loss_criterion(y_pred,y_true)\n",
    "            eval_loss+=loss.item()\n",
    "            y_predicted.append(y_pred.item())\n",
    "            y_actual.append(y_true.item())\n",
    "            \n",
    "        pred_perf=pp(y_predicted, y_actual)\n",
    "    print('Epoch: {}/{} | Evaluation_Loss: {} | Pred. Power: {}'.format(epoch-epochs+1, num_epochs, eval_loss, pred_perf))        \n",
    "    plt.plot(range(len(y_predicted)),y_predicted,color='red')\n",
    "    plt.plot(range(len(y_actual)),y_actual,color='blue')\n",
    "    #print(len(y_predicted),len(y_actual))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return eval_loss,pred_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=EncoderRNN(encoder_input_size = 2)\n",
    "decoder = DecoderRNN()\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "criterion=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-de02e3f22f53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_perf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval_loss: {}  pred_perf: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_perf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2ab83c0eb04a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, encoder_optimizer, decoder_optimizer, train_loader, loss_criterion, rl, num_epochs, epoch, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#        hidden=encoder.initHidden(16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mencoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#        hidden=decoder.initHidden(16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#        y_pred=decoder(encoded,y,16,hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'batch_size'"
     ]
    }
   ],
   "source": [
    "rl=[]\n",
    "num_epochs=20\n",
    "epochs=0\n",
    "for epoch in range(epochs,epochs+num_epochs):\n",
    "    train(encoder,decoder,encoder_optimizer, decoder_optimizer,train_loader,criterion,rl,num_epochs, epoch, epochs)\n",
    "    eval_loss, pred_perf=evaluate(encoder,decoder, val_loader, criterion, num_epochs, epoch, epochs)\n",
    "    print('eval_loss: {}  pred_perf: {}'.format(eval_loss, pred_perf))\n",
    "    if (eval_loss<0.01 and pred_perf>0.5):\n",
    "        print ('%---Saving the model---%')\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "            'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "            'loss': rl,\n",
    "            },'models/OpenPrice/model_{}.pth'.format(epoch+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "eval_loss=0\n",
    "y_predicted=[]\n",
    "y_actual=[]\n",
    "with torch.no_grad():\n",
    "    for i,sample in enumerate(val_loader):\n",
    "        x=sample['X'].type(torch.FloatTensor)\n",
    "        y=sample['targets'].type(torch.FloatTensor)\n",
    "        y_true=sample['y'].type(torch.FloatTensor)\n",
    "            \n",
    " #       hidden=encoder.initHidden(1)\n",
    "        encoded=encoder(x,1)\n",
    "#        hidden=decoder.initHidden(1)\n",
    "        y_pred=decoder(encoded,y,1)\n",
    "        \n",
    "        loss=loss_criterion(y_pred,y_true)\n",
    "        eval_loss+=loss.item()\n",
    "        y_predicted.append(y_pred.item())\n",
    "        y_actual.append(y_true.item())\n",
    "            \n",
    "        pred_perf=pp(y_predicted, y_actual)\n",
    "print('Epoch: {}/{} | Evaluation_Loss: {} | Pred. Power: {}'.format(epoch-epochs+1, num_epochs, eval_loss, pred_perf))        \n",
    "plt.plot(range(len(y_predicted)),y_predicted,color='red')\n",
    "plt.plot(range(len(y_actual)),y_actual,color='blue')\n",
    "#print(len(y_predicted),len(y_actual))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
